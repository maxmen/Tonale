{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tonale Winter School on Cosmology 2022 \n",
    "# Tutorial on Gravitational Lensing\n",
    "\n",
    "## Exercise 6: Strong Lensing mass modeling\n",
    "In this Notebook, you will learn how to model galaxies and galaxy clusters using strong lensing observations.\n",
    "\n",
    ">**Warning**: it is important that you execute the cells following the order given in the Notebook. If you execute a cell changing the value of a variable and then go back to some previous cell in the Notebook, the variable value will not change!\n",
    "\n",
    "We begin by importing some useful packages. We also import the module `lensmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some useful packages and \n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "fontsize = 15 # set the font size for labels in the plots\n",
    "co = FlatLambdaCDM(H0=70.0, Om0=0.3)\n",
    "from lensmodels import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong Lensing\n",
    "In a strong Lensing event the observables that we can use to model the lens are of three types:\n",
    "1. Positional constraints: The location of the multiple images of a given source allow us to probe the deflection field, i.e. the first derivatives of the lensing potential;\n",
    "2. Flux ratios: The flux or area ratios between the multiple images give us information about the magnification, i.e. the second derivatives of the lensing potential. Note that we don't know the intrinsic source flux, thus we can only probe the magnifications relative to one refernce image;\n",
    "3. Time delays: If the source is intrinsically variable (as supernovae, or some quasars), then the time delay between the images can be measured.\n",
    "\n",
    "In most cases, the source is not variable (for example in the case of galaxy-galaxy lensing events). In addition, the flux ratios are genereally difficult to reproduce. Indeed, they are very sensitive to perturbers, such as small clumps of matter in the lenses or along the line of sight (actually, anomalous flux ratios is an indication that some clump might be present). Thus, in the vast majority of cases, the positional constraints are the most useful piece of information to unveil the lens mass distribution.\n",
    "\n",
    "In this tutorial we focus on mostly on these constraints and show how parametric lens modeling works.\n",
    "\n",
    "\n",
    "#### Image plane optimization\n",
    "In this part, we consider the so called parametric *image plane optimization* approach: we wish to model a strong lensing event describing the lens with a parametric function and the goal is to build a model that minimizes the distances between observed and model predicted multiple images of a given source.\n",
    "\n",
    "We begin by simulating a strong lensing event. We consider a massive galaxy as lens and a distant quasar as source. In this case, the source can be assumed to be point-like. For speeding up the calculations, we assume a SIE lens with $\\theta_c=0$, i.e. the lens is singular-isothermal. This is not inconsistent with observations of strong lensing galaxies, which indicate the combination of dark matter and baryons has density profile $\\rho(r)\\propto r^{-2}$ in their central regions. The code below will not work with $\\theta_c>0$ unless the `setGrid` method is invoked after the creation of every lens instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOV = 5.0 # the Field-of-View will be FOVxFOV arcsec \n",
    "npix= 512 # the number of pixels in the maps will be (npix x npix)\n",
    "\n",
    "theta = np.linspace(-FOV/2., FOV/2, npix)\n",
    "\n",
    "zl = 0.65\n",
    "zs = 1.66\n",
    "\n",
    "kwargs_truth = {'zl': zl,\n",
    "          'zs': zs,\n",
    "          'sigma0': 250.0,\n",
    "          'q': 0.6,\n",
    "          'pa': np.deg2rad(120.0),\n",
    "          'x1': 0.0,\n",
    "          'x2': 0.0}\n",
    "\n",
    "lens_truth = sie(co,**kwargs_truth)\n",
    "lens_truth.setGrid(theta=theta) # in this case we use setGrid because we want to display the lens convergence.\n",
    "\n",
    "# we define a dictionary with the source redshift and unlensed coordinates. The flux is not relevant.\n",
    "beta1 = -0.121 \n",
    "beta2 = 0.08\n",
    "kwargs_psr_truth = {\n",
    "    'zs': zs,\n",
    "    'ys1': beta1,\n",
    "    'ys2': beta2,\n",
    "    'flux': 1.0\n",
    "}\n",
    "\n",
    "# we create an instance of the point source. \n",
    "ps=pointsrc(size=FOV, sizex=None, sizey=None, Npix=npix, gl=lens_truth, fast=True, **kwargs_psr_truth)\n",
    "# then we find its multiple images \n",
    "thetai_1, thetai_2, mui  = ps.xi1, ps.xi2, ps.mui\n",
    "\n",
    "def plot_orig(showCL_CAU):\n",
    "    fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    ax.imshow(lens_truth.ka,origin='lower',vmax=3,cmap='cubehelix_r',extent=[-FOV/2.,FOV/2.,-FOV/2.,FOV/2.])\n",
    "\n",
    "    ax.scatter(thetai_1,thetai_2,s=mui*5+15)\n",
    "\n",
    "    if showCL_CAU:\n",
    "        tancl=lens.tancl()\n",
    "        radcl=lens.radcl()\n",
    "\n",
    "        for cl in tancl:\n",
    "            cau = lens_truth.crit2cau(cl)\n",
    "            thetac2, thetac1 = cl[:,0], cl[:,1]\n",
    "            betac2, betac1 = cau[:,0], cau[:,1]\n",
    "            ax.plot(thetac1,thetac2,'--',color='white')\n",
    "            ax.plot(betac1,betac2,'-',color='white')\n",
    "\n",
    "        for cl in radcl:\n",
    "            cau = lens_truth.crit2cau(cl)\n",
    "            thetac2, thetac1 = cl[:,0], cl[:,1]\n",
    "            betac2, betac1 = cau[:,0], cau[:,1]\n",
    "            ax.plot(thetac1,thetac2,'--',color='white')\n",
    "            ax.plot(betac1,betac2,'-',color='white')\n",
    "\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.xaxis.set_tick_params(labelsize=fontsize)\n",
    "    ax.yaxis.set_tick_params(labelsize=fontsize)\n",
    "    ax.set_xlabel(r'$\\theta_1$',fontsize=fontsize)\n",
    "    ax.set_ylabel(r'$\\theta_2$',fontsize=fontsize)\n",
    "    return fig,ax\n",
    "\n",
    "fig,ax=plot_orig(showCL_CAU=False)\n",
    "\n",
    "print (('Lens type %s, Einst. radius %f') % (lens_truth.lens_type,lens_truth.bsie()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue circles in the figure are the quasar multiple images. Their sizes are proportional to the image magnifications. The lens is displayed at the center. \n",
    "\n",
    "For the moment, we assume an uncertainty on the image positions $\\sigma_{ima} = 0.05\"$.\n",
    "\n",
    ">**TASK**: You may add some noise to mimic measurement uncertaintes. For example, you could generate it using a Gaussian with zero mean and standard deviation `sig`. Try repeating the fit using a few different values for this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 0.01\n",
    "s1 = np.random.normal(0.0, sig, len(thetai_1))\n",
    "s2 = np.random.normal(0.0, sig, len(thetai_2))\n",
    "thetai_obs_1=thetai_1+s1\n",
    "thetai_obs_2=thetai_2+s2\n",
    "sigma_ima=np.zeros(len(thetai_1))+0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to write a function that maps the observed image positions onto the source plane using the lens equation:\n",
    "$$\n",
    "\\beta_{1,i}=\\theta_{1,i}-\\alpha_{1,i}(\\theta_{1,i},\\theta_{2,i}) \n",
    "$$\n",
    "$$\n",
    "\\beta_{2,i}=\\theta_{2,i}-\\alpha_{2,i}(\\theta_{1,i},\\theta_{2,i}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that calculates the source positions of an ensemble of point images\n",
    "def guess_source(lens_m,thetai_1,thetai_2):\n",
    "    # calculate the deflection angle at the image positions\n",
    "    a1, a2 = lens_m.angle(thetai_1,thetai_2)\n",
    "    # use lens equation to find source positions\n",
    "    betai_1=thetai_1-a1\n",
    "    betai_2=thetai_2-a2\n",
    "    return betai_1, betai_2\n",
    "\n",
    "# Test code:\n",
    "betai1,betai2 = guess_source(lens_truth,thetai_1,thetai_2)\n",
    "print ('Guessed beta1',betai1,'Truth:',kwargs_psr_truth['ys1'])\n",
    "print ('Guessed beta2',betai2,'Truth:',kwargs_psr_truth['ys2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `guess_source` takes the image positions $(\\theta_{1,i},\\theta_{2,i})$ and returns a guessed source position $(\\beta_{1,i},\\beta_{2,i})$ for each observed image. So, if we observe four images, then\n",
    "\n",
    "Now, we can start describing the fitting process. Remember: we don't know anything about the lens. Let's make a guess about the lens parameters and use the lens equation to map the images onto the source plane:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_model = {'zl': zl,\n",
    "          'zs': zs,\n",
    "          'sigma0': 230.0,\n",
    "          'q': 0.45,\n",
    "          'pa': np.deg2rad(164.0),\n",
    "          'x1': 0.0,\n",
    "          'x2': 0.0}\n",
    "\n",
    "lens_model = sie(co,**kwargs_model)\n",
    "lens_model.setGrid(theta)\n",
    "\n",
    "betai1,betai2 = guess_source(lens_model,thetai_obs_1,thetai_obs_2)\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(5,5))\n",
    "tancl=lens_model.tancl()\n",
    "radcl=lens_model.radcl()\n",
    "\n",
    "for cl in tancl:\n",
    "    cau = lens_model.crit2cau(cl)\n",
    "    betac2, betac1 = cau[:,0], cau[:,1]\n",
    "    ax.plot(betac1,betac2,'-',color='black')\n",
    "\n",
    "for cl in radcl:\n",
    "    cau = lens_model.crit2cau(cl)\n",
    "    betac2, betac1 = cau[:,0], cau[:,1]\n",
    "    ax.plot(betac1,betac2,'-',color='black')\n",
    "\n",
    "ax.scatter(betai1,betai2,marker='*',color='yellow',edgecolor='black',s=80,label='Guessed source pos.')\n",
    "\n",
    "best_beta1 = betai1.mean()\n",
    "best_beta2 = betai2.mean()\n",
    "\n",
    "ax.scatter(best_beta1,best_beta2,marker='*',color='blue',edgecolor='black',s=80,label='Guessed source pos. (mean)')\n",
    "\n",
    "ax.plot(kwargs_psr_truth['ys1'],kwargs_psr_truth['ys2'],'o',ms=8,color='red',label='True source pos.',zorder=-1)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim([-1,1])\n",
    "ax.set_ylim([-1,1])\n",
    "ax.legend(fontsize=fontsize)\n",
    "ax.xaxis.set_tick_params(labelsize=fontsize)\n",
    "ax.yaxis.set_tick_params(labelsize=fontsize)\n",
    "ax.set_xlabel(r'$\\beta_1$',fontsize=fontsize)\n",
    "ax.set_ylabel(r'$\\beta_2$',fontsize=fontsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we found four well separated sources (indicted by yellow stars), because the lens model is not correct. We may assume that the best guess for the source position is the mean position of these four sources (blue star). Let's try to map this star back to the lens plane: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_psr = {\n",
    "    'zs': zs,\n",
    "    'ys1': best_beta1,\n",
    "    'ys2': best_beta2,\n",
    "    'flux': 1.0\n",
    "}\n",
    "\n",
    "# we create an instance of the point source. \n",
    "ps=pointsrc(size=FOV, sizex=None, sizey=None, Npix=npix, gl=lens_model, fast=True, **kwargs_psr)\n",
    "# then we find its multiple images \n",
    "thetai_1_guess, thetai_2_guess, mui_guess = ps.xi1, ps.xi2, ps.mui  \n",
    "\n",
    "\n",
    "fig,ax=plot_orig(showCL_CAU=False)\n",
    "ax.scatter(thetai_1_guess, thetai_2_guess, s=mui_guess*5+1,color='orange',zorder=20,edgecolor='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quantify how bad our guess is by defining a cost function that compares the true image positions with those predicted by the model. In computing the cost function, the trickiest part regards the pairing of observed and model predicted positions. In the implementation below, I created two lists of coordinates and searched for unique pairs from the two lists based on the point distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(thetai_1, thetai_2, thetai_1_guess, thetai_2_guess):\n",
    "    # iterate by value\n",
    "    coords_obs = [(thetai_1[i],thetai_2[i]) for i in range(len(thetai_1))]\n",
    "    coords_guess = [(thetai_1_guess[i],thetai_2_guess[i]) for i in range(len(thetai_1_guess))]\n",
    "    cost=[]\n",
    "    for list1_val in coords_obs:\n",
    "        # stop when list2 is empty\n",
    "        if len(coords_guess) == 0:\n",
    "            break\n",
    "        # find the closest match\n",
    "        list2_val = min(coords_guess, key=lambda x:(x[0]-list1_val[0])**2+(x[1]-list1_val[1])**2)\n",
    "        d = (list1_val[0]-list2_val[0])**2+(list1_val[1]-list2_val[1])**2\n",
    "        cost.append(d)\n",
    "        # remove the match from list2\n",
    "        coords_guess.remove(list2_val)\n",
    "        ax.plot([list1_val[0],list2_val[0]],[list1_val[1],list2_val[1]],'-',color='blue')\n",
    "    # if the model predicts fewer images than observed\n",
    "    # we penalize the solution\n",
    "    if len(coords_guess) < len(coords_obs):\n",
    "        idiff = len(coords_guess)-len(coords_obs)\n",
    "        for i in range(idiff):\n",
    "            cost.append(100.0)\n",
    "    return np.array(cost).sum()\n",
    "    \n",
    "\n",
    "fig,ax=plot_orig(showCL_CAU=False)\n",
    "ax.scatter(thetai_1_guess, thetai_2_guess, s=mui_guess*5+1,color='orange',zorder=20,edgecolor='black')\n",
    "print (('Cost function %.4f') % cost_function(thetai_obs_1, thetai_obs_2, thetai_1_guess, thetai_2_guess))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of parametric modeling is to minimize the cost function by varying the model parameters. Looking at the image above, we will try to reduce the size of the blue sticks connecting the observed image positions (blue circles) to the predicted image positions (orange circles). This is the key objective of the image plane optimization.\n",
    "\n",
    "There are several algorithms that one can use to perform the lens optimization. In this Notebook we use a Non-Linear Least-Squares Minimization package called [`lmfit`](https://lmfit.github.io/lmfit-py/index.html). This package allows building complex fitting models for non-linear least-squares problems. The implementation shown here was obtained by closely following the examples in the package documentation, which can be found at [this link](http://​cars9.​uchicago.​edu/​software/​python/​lmfit_​MinimizerResult/​intro.​html).\n",
    "\n",
    "We begin by setting up some initial guesses for the model parameters, storing them in a lmfit.Parameter object, including also some plausible ranges where the parameters can vary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "# initial guesses. For each parameter we indicate:\n",
    "# - the name ('sigma0')\n",
    "# - the initial guess (200.)\n",
    "# - if the parameter is free to vary (True)\n",
    "# - the range within the values can vary (100,300). The priors are uniform.\n",
    "\n",
    "p = lmfit.Parameters()\n",
    "p.add_many(('sigma0', 200.,True, 100,300),('q', 0.5, True, 0.2, 1.0), \n",
    "           ('pa', 100.0, True, 80., 150.),('x1', 0.0, False, -1., 1.),('x2', 0.0, False, -1., 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this example, we are keeping the lens position fixed (for the keys `x1` and `x2` we use the flag `False` to indicate that their values cannot vary).\n",
    "\n",
    "In the next cell, we re-write the cost function above in a way that can be used by `lmfit` to optimize the model. In particular, the function accepts the `lmfit.Parameters` object as input and creates the lens instance used to guess the image positions. In addition, the cost value is returned in terms of lists of residuals between the observed and guessed image positions (the length of the blue sticks in the previous figure). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(p,thetai_1, thetai_2, sigma_ima):\n",
    "\n",
    "    kwargs_model = {'zl': zl,\n",
    "          'zs': zs,\n",
    "          'sigma0': p['sigma0'],\n",
    "          'q': p['q'],\n",
    "          'pa': np.deg2rad(p['pa']),\n",
    "          'x1': p['x1'],\n",
    "          'x2': p['x2']}\n",
    "    lens_model = sie(co,**kwargs_model)\n",
    "    #lens_model.setGrid(theta)\n",
    "\n",
    "    betai1,betai2 = guess_source(lens_model,thetai_1,thetai_2)\n",
    "    best_beta1 = betai1.mean()\n",
    "    best_beta2 = betai2.mean()\n",
    "\n",
    "    kwargs_psr = {\n",
    "        'zs': zs,\n",
    "        'ys1': best_beta1,\n",
    "        'ys2': best_beta2,\n",
    "        'flux': 1.0\n",
    "    }\n",
    "\n",
    "    # we create an instance of the point source. \n",
    "    ps=pointsrc(size=FOV, sizex=None, sizey=None, Npix=npix, gl=lens_model, fast=True, **kwargs_psr)\n",
    "\n",
    "    #then we find its multiple images \n",
    "    thetai_1_guess, thetai_2_guess = ps.xi1, ps.xi2\n",
    "    #print (len(thetai_1_guess),len(thetai_1))\n",
    "\n",
    "    # iterate by value\n",
    "    coords_obs = [(thetai_1[i],thetai_2[i]) for i in range(len(thetai_1))]\n",
    "    coords_guess = [(thetai_1_guess[i],thetai_2_guess[i]) for i in range(len(thetai_1_guess))]\n",
    "    cost1=[]\n",
    "    cost2=[]\n",
    "\n",
    "    for list1_val in coords_obs:\n",
    "        # stop when list2 is empty\n",
    "        if len(coords_guess) == 0:\n",
    "            break\n",
    "        # find the closest match\n",
    "        list2_val = min(coords_guess, key=lambda x:(x[0]-list1_val[0])**2+(x[1]-list1_val[1])**2)\n",
    "        \n",
    "        cost1.append(list1_val[0]-list2_val[0])\n",
    "        cost2.append(list1_val[1]-list2_val[1])\n",
    "        \n",
    "        # remove the match from list2\n",
    "        coords_guess.remove(list2_val)\n",
    "       \n",
    "    # if the model predicts fewer images than observed\n",
    "    # we penalize the solution\n",
    "\n",
    "    if len(thetai_1_guess) < len(thetai_1):\n",
    "        idiff = len(thetai_1) - len(thetai_1_guess)\n",
    "        for i in range(idiff):\n",
    "            cost1.append(100.0)\n",
    "            cost2.append(100.0)\n",
    "\n",
    "    return np.array(cost1)/sigma_ima, np.array(cost2)/sigma_ima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to minimize the cost function (i.e. the residuals) to fit the data. We do that by using the `lmfit.minimize` function. Several algorithms are available in `lmfit`. Here, we perform the minimization using the [Powell](https://en.wikipedia.org/wiki/Powell%27s_method) optimization algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_ip = lmfit.minimize(residual, p, method='Powell', args=(thetai_obs_1, thetai_obs_2, sigma_ima))\n",
    "\n",
    "lmfit.printfuncs.report_fit(mi_ip.params, min_correl=0.5)\n",
    "print (lmfit.fit_report(mi_ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit seems to be successful! Let's visualize how the best fit model predicts the observed image positions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_model_ip = {'zl': zl,\n",
    "          'zs': zs,\n",
    "          'sigma0': mi_ip.params['sigma0'],\n",
    "          'q': mi_ip.params['q'],\n",
    "          'pa': np.deg2rad(mi_ip.params['pa']),\n",
    "          'x1': mi_ip.params['x1'],\n",
    "          'x2': mi_ip.params['x2']}\n",
    "\n",
    "lens_model_ip = sie(co,**kwargs_model_ip)\n",
    "#lens_model.setGrid(theta)\n",
    "\n",
    "betai1,betai2 = guess_source(lens_model_ip,thetai_obs_1,thetai_obs_2)\n",
    "best_beta1 = betai1.mean()\n",
    "best_beta2 = betai2.mean()\n",
    "\n",
    "kwargs_psr = {\n",
    "    'zs': zs,\n",
    "    'ys1': best_beta1,\n",
    "    'ys2': best_beta2,\n",
    "    'flux': 1.0\n",
    "}\n",
    "\n",
    "# we create an instance of the point source. \n",
    "ps=pointsrc(size=FOV, sizex=None, sizey=None, Npix=npix, gl=lens_model_ip, fast=True, **kwargs_psr)\n",
    "\n",
    "#then we find its multiple images \n",
    "thetai_1_guess, thetai_2_guess, mui_guess = ps.xi1, ps.xi2, ps.mui\n",
    "\n",
    "fig,ax=plot_orig(showCL_CAU=False)\n",
    "ax.scatter(thetai_1_guess, thetai_2_guess, s=mui_guess*5+1,color='orange',zorder=20,edgecolor='black')\n",
    "\n",
    "print (('Cost function %.4f') % cost_function(thetai_obs_1, thetai_obs_2, thetai_1_guess, thetai_2_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a Bayesian sampling of the posterior probability distribution of the parameters using the ensemble sampler for Markov chain Monte Carlo (MCMC) implemented in the Python package [`emcee`](https://emcee.readthedocs.io/en/stable/). This can be achieved again by using the `lmfit.minimize` function with the `emcee` method.\n",
    "\n",
    "Note that for doing this, the cost function has been redefined such as to return a float value, i.e. the $\\chi^2(p)$, as specified by setting `float_behavior=’chi2’` in the function call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2(p,thetai_1, thetai_2, sigma_ima):\n",
    "    d1,d2=residual(p,thetai_1, thetai_2, sigma_ima)\n",
    "    return np.sqrt(d1**2+d2**2)\n",
    "\n",
    "res = lmfit.minimize(chi2, method='emcee', nan_policy='omit', burn=300, steps=2000, nwalkers=100,\n",
    "                     params=mi_ip.params, float_behavior='chi2', is_weighted=True, progress=True,args=(thetai_obs_1, thetai_obs_2, sigma_ima))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the `corner` package to display the posterior distributions of the model parameters. Such plot gives you a lot of information about the model, including possible degeneracies between the parameters, how well are the parameters constrained, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "figure = corner.corner(res.flatchain, labels=[r\"$\\sigma_0$\", r\"$q$\", r\"$\\varphi$\"],\n",
    "                       truths=[kwargs_truth['sigma0'],kwargs_truth['q'],np.rad2deg(kwargs_truth['pa'])],\n",
    "                       quantiles=[0.16, 0.84],\n",
    "                       show_titles=True, title_kwargs={\"fontsize\": 14}, label_kwargs={\"fontsize\": 14})\n",
    "for ax in figure.get_axes():\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "#figure.savefig('corner_sie_with_offset.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source plane optimization\n",
    "As we could experience, the image plane optimization can take time. This kind of optimization is often computationally demanding, because it requires to find the solutions of the lens equation at each iteration and for each family of multiple images. Immagine the lens is a galaxy cluster lensing a hundred galaxies simultaneously. Since the lens requires the combination of several mass components and there are many families of multiple images, the Bayesian analysis can take more than a month even with codes that include parallelization!\n",
    "\n",
    "There is an alternative and faster approach that consists of finding the best combination of model parameters that minimizes the scatter between the predicted source positions obtained by de-lensing each family of multiple images. This process is called **Optimization in the source plane**.\n",
    "\n",
    "We can implement this optimization very easily by writing the appropriate cost function. First, of all let's make a plot to illustrate the problem. Let's make a guess about the source position using an initial model and repropose a figure shown earlier:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_model = {'zl': zl,\n",
    "          'zs': zs,\n",
    "          'sigma0': 230.0,\n",
    "          'q': 0.45,\n",
    "          'pa': np.deg2rad(164.0),\n",
    "          'x1': 0.0,\n",
    "          'x2': 0.0}\n",
    "\n",
    "lens_model = sie(co,**kwargs_model)\n",
    "lens_model.setGrid(theta)\n",
    "\n",
    "betai1,betai2 = guess_source(lens_model,thetai_obs_1,thetai_obs_2)\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(5,5))\n",
    "tancl=lens_model.tancl()\n",
    "radcl=lens_model.radcl()\n",
    "\n",
    "for cl in tancl:\n",
    "    cau = lens_model.crit2cau(cl)\n",
    "    betac2, betac1 = cau[:,0], cau[:,1]\n",
    "    ax.plot(betac1,betac2,'-',color='black')\n",
    "\n",
    "for cl in radcl:\n",
    "    cau = lens_model.crit2cau(cl)\n",
    "    betac2, betac1 = cau[:,0], cau[:,1]\n",
    "    ax.plot(betac1,betac2,'-',color='black')\n",
    "\n",
    "ax.scatter(betai1,betai2,marker='*',color='yellow',edgecolor='black',s=80,label='Guessed source pos.')\n",
    "\n",
    "best_beta1 = betai1.mean()\n",
    "best_beta2 = betai2.mean()\n",
    "\n",
    "ax.scatter(best_beta1,best_beta2,marker='*',color='blue',edgecolor='black',s=80,label='Guessed source pos. (mean)')\n",
    "\n",
    "for i in range(len(betai1)):\n",
    "    ax.plot([betai1[i],best_beta1],[betai2[i],best_beta2],'-',color='blue')\n",
    "\n",
    "#ax.plot(kwargs_psr['ys1'],kwargs_psr['ys2'],'o',ms=8,color='red',label='True source pos.')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim([-1,1])\n",
    "ax.set_ylim([-1,1])\n",
    "ax.legend(fontsize=fontsize)\n",
    "ax.xaxis.set_tick_params(labelsize=fontsize)\n",
    "ax.yaxis.set_tick_params(labelsize=fontsize)\n",
    "ax.set_xlabel(r'$\\beta_1$',fontsize=fontsize)\n",
    "ax.set_ylabel(r'$\\beta_2$',fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distances between the best guessed source position and and the predicted position from each individual image are represented by blue sticks. The goal of the source plane optimisation is to make these sticks as short as possible by varying the model parameters. Indeed, the correct lens model should map all multiple images onto the same source.\n",
    "\n",
    "We could write the cost function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals_sp(p,thetai_1, thetai_2, sigma_src):\n",
    "\n",
    "    kwargs_model = {'zl': zl,\n",
    "          'zs': zs,\n",
    "          'sigma0': p['sigma0'],\n",
    "          'q': p['q'],\n",
    "          'pa': np.deg2rad(p['pa']),\n",
    "          'x1': p['x1'],\n",
    "          'x2': p['x2']}\n",
    "    lens_model = sie(co,**kwargs_model)\n",
    "    #lens_model.setGrid(theta)\n",
    "\n",
    "    betai1,betai2 = guess_source(lens_model,thetai_1,thetai_2)\n",
    "    best_beta1 = betai1.mean()\n",
    "    best_beta2 = betai2.mean()\n",
    "\n",
    "    cost1=[]\n",
    "    cost2=[]\n",
    "    for i in range(len(betai1)):\n",
    "        cost1.append(betai1[i]-best_beta1)\n",
    "        cost2.append(betai2[i]-best_beta2)\n",
    "\n",
    "    return np.array(cost1)/sigma_src, np.array(cost2)/sigma_src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we just need to repeat the same steps from the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = lmfit.Parameters()\n",
    "p.add_many(('sigma0', 200.,True, 100,300),('q', 0.5, True, 0.2, 1.0), \n",
    "           ('pa', 100.0, True, 80., 150.),('x1', 0.0, False, -1., 1.),('x2', 0.0, False, -1., 1.))\n",
    "\n",
    "sigma_src=np.ones(len(thetai_obs_1))*0.05\n",
    "mi_src = lmfit.minimize(residuals_sp, p, method='Powell', args=(thetai_obs_1, thetai_obs_2, sigma_src))\n",
    "\n",
    "lmfit.printfuncs.report_fit(mi_src.params, min_correl=0.5)\n",
    "print (lmfit.fit_report(mi_src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the Bayesian analysis, we re-define the cost function as before, and call `lmfit.minimize` with the `emcee` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_sp(p,thetai_1, thetai_2, sigma_src):\n",
    "    d1,d2=residuals_sp(p,thetai_1, thetai_2, sigma_src)\n",
    "    return np.sqrt(d1**2+d2**2)\n",
    "\n",
    "res_src = lmfit.minimize(chi2_sp, method='emcee', nan_policy='omit', burn=300, steps=2000, nwalkers=100,\n",
    "                     params=mi_src.params, float_behavior='chi2', is_weighted=True, progress=True,args=(thetai_obs_1, thetai_obs_2, sigma_ima))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = corner.corner(res_src.flatchain, labels=[r\"$\\sigma_0$\", r\"$q$\", r\"$\\varphi$\"],\n",
    "                       truths=[kwargs_truth['sigma0'],kwargs_truth['q'],np.rad2deg(kwargs_truth['pa'])],\n",
    "                       quantiles=[0.16, 0.84],\n",
    "                       show_titles=True, title_kwargs={\"fontsize\": 14}, label_kwargs={\"fontsize\": 14})\n",
    "for ax in figure.get_axes():\n",
    "    ax.tick_params(axis='both', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this idealized example, the optimization on the source and image planes perform similarly. Let see how the best fit model based on source plane optimization reprodues the observed multiple images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_model_sp = {'zl': zl,\n",
    "          'zs': zs,\n",
    "          'sigma0': mi_src.params['sigma0'],\n",
    "          'q': mi_src.params['q'],\n",
    "          'pa': np.deg2rad(mi_src.params['pa']),\n",
    "          'x1': mi_src.params['x1'],\n",
    "          'x2': mi_src.params['x2']}\n",
    "\n",
    "lens_model_sp = sie(co,**kwargs_model_sp)\n",
    "#lens_model.setGrid(theta)\n",
    "\n",
    "betai1,betai2 = guess_source(lens_model_sp,thetai_obs_1,thetai_obs_2)\n",
    "best_beta1 = betai1.mean()\n",
    "best_beta2 = betai2.mean()\n",
    "\n",
    "kwargs_psr = {\n",
    "    'zs': zs,\n",
    "    'ys1': best_beta1,\n",
    "    'ys2': best_beta2,\n",
    "    'flux': 1.0\n",
    "}\n",
    "\n",
    "# we create an instance of the point source. \n",
    "ps=pointsrc(size=FOV, sizex=None, sizey=None, Npix=npix, gl=lens_model_sp, fast=True, **kwargs_psr)\n",
    "\n",
    "#then we find its multiple images \n",
    "thetai_1_guess, thetai_2_guess, mui_guess = ps.xi1, ps.xi2, ps.mui\n",
    "\n",
    "fig,ax=plot_orig(showCL_CAU=False)\n",
    "ax.scatter(thetai_1_guess, thetai_2_guess, s=mui_guess*5+1,color='orange',zorder=20,edgecolor='black')\n",
    "print (cost_function(thetai_obs_1, thetai_obs_2, thetai_1_guess, thetai_2_guess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lens model allow us to investigate how the matter (dark and baryonic) is distributed inside the lens.\n",
    "\n",
    ">**TASK**: make a plot comparing the true and the recovered mass distributions of the lens. Start with the convergence and convert it to solar masses using the function `SigmaCrit` shown below.  Measure the total mass within the FOV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def SigmaCrit(lens):\n",
    "    from astropy.constants import c, G\n",
    "    c2_G_Msun_Mpc = (c**2/G).to(u.Msun/u.Mpc)\n",
    "    sigma_cr = c2_G_Msun_Mpc/(4*np.pi)*(lens.ds/lens.dl/lens.dls)\n",
    "    return(sigma_cr)\n",
    "\n",
    "lens_model_ip.setGrid(theta=theta)\n",
    "lens_model_sp.setGrid(theta=theta)\n",
    "\n",
    "\n",
    "sigmacr = SigmaCrit(lens_truth)\n",
    "print ('Sigma_crit=',sigmacr)\n",
    "\n",
    "\n",
    "pixel = np.deg2rad(lens_truth.pixel_scale/3600.0)*lens_truth.dl\n",
    "print ('pixel scale=',pixel)\n",
    "\n",
    "# to get rid of units:\n",
    "pixel = pixel.value\n",
    "sigmacr = sigmacr.value\n",
    "\n",
    "#\n",
    "fig,ax = plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "\n",
    "# TODO: COMPLETE THE CODE BELOW: display the convergence maps of the best fit models obtained from the image and source plane optimizations\n",
    "ax[0].imshow(np.log10(lens_truth.ka),origin='lower',cmap='cubehelix',extent=[-FOV/2.,FOV/2.,-FOV/2.,FOV/2.])\n",
    "ax[1].imshow(np.log10(...),origin='lower',cmap='cubehelix',extent=[-FOV/2.,FOV/2.,-FOV/2.,FOV/2.])\n",
    "ax[2].imshow(np.log10(...),origin='lower',cmap='cubehelix',extent=[-FOV/2.,FOV/2.,-FOV/2.,FOV/2.])\n",
    "\n",
    "for ax_ in ax:\n",
    "    ax_.xaxis.set_tick_params(labelsize=fontsize)\n",
    "    ax_.yaxis.set_tick_params(labelsize=fontsize)\n",
    "    ax_.set_xlabel(r'$\\theta_1$',fontsize=fontsize)\n",
    "    ax_.set_ylabel(r'$\\theta_2$',fontsize=fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "#TODO: COMPLETE THE CODE BELOW: calculate the mass within the FOV (in solar masses)\n",
    "print (('True mass %10.4e solMass') % (...))\n",
    "print (('IP opt. %10.4e solMass') % (...))\n",
    "print (('SP opt. %10.4e solMass') % (...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do these images remind anything to you? :-)\n",
    "\n",
    "![WFI2033](./data/WFI2033.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try yourself!\n",
    "\n",
    ">**TASK**: Try to fit using a SIE model with $\\theta_c=0$ the lens system in the Figure below.\n",
    "\n",
    "![Your next task](./data/mysteriouslens.png)\n",
    "\n",
    "The coordinates of the multiple images are:\n",
    "\n",
    "| Image | $\\theta_1$ | $\\theta_2$ |\n",
    "|-------|------------|------------|\n",
    "|   A   | 0.20956365 | 0.97871616 |\n",
    "|   B   | -0.97871616| -0.20956365|\n",
    "|   C   | -0.66800501| 0.66800501 |\n",
    "|   D . | 0.44537728 | -0.44537728|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer these questions:\n",
    "\n",
    ">**TASK**: Suppose you have measured the time delays between the images. How would you implement a cost function that accounts for both the positional constraints and the time delays?\n",
    "\n",
    ">**TASK**: Consider the lens below. How would you implement a cost function to fit two families of multiple images?\n",
    "\n",
    "![Your next task](./data/compoundlens.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('tonale')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80049abdef48e04a217b57438db502bd877ddf91a719032c10ed240a9419ff14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
